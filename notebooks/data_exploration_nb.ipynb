{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANALYSIS QUESTIONS**\n",
    "\n",
    "1. Discover relationship between Total Complexity Points (as of May 2021) and subsequent PRODUCTION, OUTFLOW, and NET. 9 months is probably preferred, but explore whether there are differences between 3 and 6 months.\n",
    "\n",
    "2. Same as above, but for each individual Complexity input   (also, including the data on \"Other Data\" tab as separate variables).\n",
    "\n",
    "3. Create simple model that tries to predict which clients will contribute over $1,000,000 in production in 9 months based on Complexity data only. Is there a \"formula\" for complexity that indicates that the client WILL, WON'T ever contribute significant production?\n",
    "\n",
    "4. Explore link between Complexity Points and # of Meetings, Zooms, calls in subsequent 9 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, RFE, VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import mca\n",
    "import prince\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set view options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in excel spreadsheets\n",
    "complexity = pd.read_excel('../data/RohitCapstoneDataApr2022.xlsx', sheet_name = 'Complexity Data') \\\n",
    "    .rename(columns = {'rel_id': 'RelID', 'ComplexityRuleID': 'RuleID', 'ComplexityRuleType': 'RuleType'})\n",
    "\n",
    "prod_outflow_columns = {\n",
    "    'rel_id': 'RelID', \n",
    "    'CurrentRelValue': 'CurrentValue',\n",
    "    'Beginning Rel Value': 'BeginningValue',\n",
    "    'ThreeMonthProd': '3MonthProd',\n",
    "    'SixMonthProd': '6MonthProd',\n",
    "    'NineMonthProd': '9MonthProd',\n",
    "    'ThreeMonthOutflow': '3MonthOutflow',\n",
    "    'SixMonthOutflow': '6MonthOutflow',\n",
    "    'NineMonthOutflow': '9MonthOutflow'\n",
    "}\n",
    "prod_outflow = pd.read_excel('../data/RohitCapstoneDataApr2022.xlsx', sheet_name = 'Prod-Outflow Data', skiprows = 1) \\\n",
    "    .rename(columns = prod_outflow_columns)[prod_outflow_columns.values()]\n",
    "\n",
    "other = pd.read_excel('../data/RohitCapstoneDataApr2022.xlsx', sheet_name = 'Other Data as of 202105') \\\n",
    "    .drop(columns = 'AsOf')\n",
    "\n",
    "meetings = pd.read_excel('../data/RohitCapstoneDataApr2022.xlsx', sheet_name = 'Subsequent Mtgs', converters = {'AsOf': str})\n",
    "date_filter = ['202106', '202107', '202108', '202109', '202110', '202111', '202112', '202201', '202202', '202203', '202204']\n",
    "meetings = meetings.loc[meetings['AsOf'].isin(date_filter)]\n",
    "meetings['Year'] = meetings['AsOf'].str[0:4]\n",
    "meetings['Month'] = meetings['AsOf'].str[4:6]\n",
    "meetings['Interactions'] = meetings['Call'] + meetings['Meeting'] + meetings['Zoom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show complexity rules\n",
    "complexity_table = complexity[['RuleID', 'RuleType', '# Pts', 'Name']].sort_values('RuleID').drop_duplicates().reset_index(drop = True)\n",
    "complexity_table = complexity_table.merge(complexity.value_counts('RuleID').to_frame('# RelIDs'), on = 'RuleID')\n",
    "complexity_table\n",
    "# complexity_table.style.set_properties(**{'text-align': 'left'}).set_table_styles([dict(selector = 'th', props=[('text-align', 'left')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show meeting categories\n",
    "meetings[['CategoryName']].drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group non-client review meetings together \n",
    "meetings.loc[meetings['CategoryName'] != 'Client Review', 'CategoryName'] = 'Everything Else'\n",
    "\n",
    "# Sum up interactions by year, month, and meeting type \n",
    "meetings.loc[meetings['CategoryName'] == 'Client Review'].groupby(['Year', 'Month', 'CategoryName'], as_index = False)['Interactions'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize accounts by BeginningValue\n",
    "print('Total Accounts: ' + str(len(prod_outflow)))\n",
    "print('Accounts with BeginningValue less than $500,000: ' + str(sum(prod_outflow['BeginningValue'] < 500000)))\n",
    "print('Accounts with BeginningValue less than $250,000: ' + str(sum(prod_outflow['BeginningValue'] < 250000)))\n",
    "print('Accounts with BeginningValue less than $100,000: ' + str(sum(prod_outflow['BeginningValue'] < 100000)))\n",
    "print('Accounts with BeginningValue equal to $0: ' + str(sum(prod_outflow['BeginningValue'] == 0)))\n",
    "print('Accounts with BeginningValue less than $0: ' + str(sum(prod_outflow['BeginningValue'] < 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter accounts with BeginningValue less than $500,000\n",
    "prod_outflow = prod_outflow[prod_outflow['BeginningValue'] >= 500000]\n",
    "\n",
    "# Calculate net, net percentage, and percentage change variables\n",
    "prod_outflow['3MonthNet'] = prod_outflow['3MonthProd'] + prod_outflow['3MonthOutflow']\n",
    "prod_outflow['6MonthNet'] = prod_outflow['6MonthProd'] + prod_outflow['6MonthOutflow']\n",
    "prod_outflow['9MonthNet'] = prod_outflow['9MonthProd'] + prod_outflow['9MonthOutflow']\n",
    "\n",
    "prod_outflow['3MonthNetPct'] = prod_outflow['3MonthNet'] / prod_outflow['BeginningValue'] * 100\n",
    "prod_outflow['6MonthNetPct'] = prod_outflow['6MonthNet'] / prod_outflow['BeginningValue'] * 100\n",
    "prod_outflow['9MonthNetPct'] = prod_outflow['9MonthNet'] / prod_outflow['BeginningValue'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize accounts by 9MonthProd\n",
    "print('Total Accounts: ' + str(len(prod_outflow)))\n",
    "print('Accounts with Production >= $1M: ' + str(sum(prod_outflow['9MonthProd'] >= 1000000)))\n",
    "print('Accounts with Production between $500k-$1M: ' + str(sum((prod_outflow['9MonthProd'] >= 500000) & (prod_outflow['9MonthProd'] < 1000000))))\n",
    "print('Accounts with Production between $250k-$500k: ' + str(sum((prod_outflow['9MonthProd'] >= 250000) & (prod_outflow['9MonthProd'] < 500000))))\n",
    "print('Accounts with Production between $100k-$250k: ' + str(sum((prod_outflow['9MonthProd'] >= 100000) & (prod_outflow['9MonthProd'] < 250000))))\n",
    "print('Accounts with Production between $50k-$100k: ' + str(sum((prod_outflow['9MonthProd'] >= 50000) & (prod_outflow['9MonthProd'] < 100000))))\n",
    "print('Accounts with Production between $0-$50k: ' + str(sum((prod_outflow['9MonthProd'] > 0) & (prod_outflow['9MonthProd'] < 50000))))\n",
    "print('Accounts with Production == $0: ' + str(sum(prod_outflow['9MonthProd'] == 0)))\n",
    "print('Accounts with Production < $0: ' + str(sum(prod_outflow['9MonthProd'] < 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up complexity points per RelID\n",
    "complexity_pts = complexity.groupby('RelID', as_index = False)['# Pts'].sum()\n",
    "\n",
    "# Sum up client interactions per RelID\n",
    "interactions = meetings.loc[meetings['CategoryName'] == 'Client Review'].groupby(['RelID'], as_index = False)['Interactions'].sum()\n",
    "\n",
    "# Merge complexity_pts, prod_outflow, other, and interactions data\n",
    "pts_prod_outflow = complexity_pts.merge(prod_outflow, on = 'RelID').set_index('RelID')\n",
    "pts_prod_outflow_other = pts_prod_outflow.merge(other, on = 'RelID').set_index('RelID')\n",
    "pts_prod_outflow_other_interactions = pts_prod_outflow_other.merge(interactions, how = 'left', on = 'RelID').set_index('RelID').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up complexity rule dummy variables per RelID\n",
    "complexity_rules = pd.get_dummies(complexity.set_index('RelID')['RuleID'].astype(str)).groupby('RelID').sum().reset_index()\n",
    "\n",
    "# Create ordinal complexity rule variables\n",
    "complexity_rules['2-3'] = complexity_rules['2'] * 1 + complexity_rules['3'] * 2\n",
    "complexity_rules['4-5'] = complexity_rules['4'] * 1 + complexity_rules['5'] * 2\n",
    "complexity_rules['6-7'] = complexity_rules['6'] * 1 + complexity_rules['7'] * 2\n",
    "complexity_rules['8-9'] = complexity_rules['8'] * 1 + complexity_rules['9'] * 2\n",
    "complexity_rules['10-13'] = complexity_rules['10'] * 1 + complexity_rules['11'] * 2 + complexity_rules['12'] * 3 + complexity_rules['13'] * 4\n",
    "complexity_rules['14-16'] = complexity_rules['14'] * 1 + complexity_rules['15'] * 2 + complexity_rules['16'] * 3\n",
    "complexity_rules['41-43'] = complexity_rules['41'] * 1 + complexity_rules['42'] * 2 + complexity_rules['43'] * 3\n",
    "complexity_rules['49-51'] = complexity_rules['49'] * 1 + complexity_rules['50'] * 2 + complexity_rules['51'] * 3\n",
    "complexity_rules['52-53'] = complexity_rules['52'] * 1 + complexity_rules['53'] * 2\n",
    "complexity_rules['65'] = 1 - complexity_rules[['4', '5', '60']].sum(axis = 1)\n",
    "\n",
    "# Merge complexity_rules, prod_outflow, other, and interactions data\n",
    "rules_prod_outflow = complexity_rules.merge(prod_outflow, on = 'RelID').set_index('RelID')\n",
    "rules_prod_outflow_other = rules_prod_outflow.merge(other, on = 'RelID').set_index('RelID')\n",
    "rules_prod_outflow_other_interactions = rules_prod_outflow_other.merge(interactions, how = 'left', on = 'RelID').set_index('RelID').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature sets\n",
    "all_rules = [\n",
    "    '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15',\n",
    "    '16', '17', '18', '19', '20', '21', '22', '23', '24', '26', '27', '28', '29', '30',\n",
    "    '31', '32', '33', '37', '38', '39', '40', '41', '42', '43', '45', '49', '50', '51',\n",
    "    '52', '53', '54', '55', '56', '57', '58', '60', '62', '63', '64'\n",
    "]\n",
    "\n",
    "collapsed_rules = [\n",
    "    '1', '2-3', '4-5', '6-7', '8-9', '10-13', '14-16', '17', '18', '19',\n",
    "    '20', '21', '22', '23', '24', '26', '27', '28', '29', '30', '31', \n",
    "    '32', '33', '37', '38', '39', '40', '41-43', '45', '49-51', '52-53',\n",
    "    '54', '55', '56', '57', '58', '62', '63', '65'\n",
    "]\n",
    "\n",
    "other_cols = [\n",
    "    'CurrentValue', 'BeginningValue', '3MonthProd', '6MonthProd', '9MonthProd',\n",
    "    '3MonthOutflow', '6MonthOutflow', '9MonthOutflow', '3MonthNet', '6MonthNet', \n",
    "    '9MonthNet', '3MonthNetPct', '6MonthNetPct', '9MonthNetPct', 'TotalUnmanagedValue',\n",
    "    'TotalCashValue', 'TotalCashUnmanagedValue', '# Accts', 'Interactions'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate crosstab heatmap of complexity points vs. client interactions\n",
    "pts_interactions = pts_prod_outflow_other_interactions[['# Pts', 'Interactions']].copy()\n",
    "\n",
    "pts_interactions.loc[pts_interactions['# Pts'] <= 3, 'Complexity Points'] = '0-3'\n",
    "pts_interactions.loc[pts_interactions['# Pts'].between(4, 6), 'Complexity Points'] = '4-6'\n",
    "pts_interactions.loc[pts_interactions['# Pts'].between(7, 9), 'Complexity Points'] = '7-9'\n",
    "pts_interactions.loc[pts_interactions['# Pts'].between(10, 13), 'Complexity Points'] = '10-13'\n",
    "pts_interactions.loc[pts_interactions['# Pts'] >= 14, 'Complexity Points'] = '14+'\n",
    "\n",
    "pts_interactions.loc[pts_interactions['Interactions'] == 0, 'Client Interactions'] = '0'\n",
    "pts_interactions.loc[pts_interactions['Interactions'] == 1, 'Client Interactions'] = '1'\n",
    "pts_interactions.loc[pts_interactions['Interactions'].between(2,3), 'Client Interactions'] = '2-3'\n",
    "pts_interactions.loc[pts_interactions['Interactions'] >= 4, 'Client Interactions'] = '4+'\n",
    "\n",
    "pts_interactions_crosstab = pd.crosstab(pts_interactions['Complexity Points'], pts_interactions['Client Interactions'])\n",
    "pts_interactions_crosstab = pts_interactions_crosstab.reindex(['14+', '10-13', '7-9', '4-6', '0-3'], axis = 'rows')\n",
    "\n",
    "plt.figure(figsize = (7, 6), dpi = 300)\n",
    "sns.heatmap(pts_interactions_crosstab, annot= True, fmt='d', cmap = plt.cm.RdBu_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pearson correlation heatmap of total complexity points vs. other variables\n",
    "# pearson_corr = pts_prod_outflow_other.corr('pearson')\n",
    "# mask = np.triu(np.ones_like(pearson_corr, dtype = bool))\n",
    "\n",
    "# plt.figure(figsize = (20, 20), dpi = 300)\n",
    "# sns.heatmap(pearson_corr, mask = mask, annot = True, fmt = '.2f', cmap = plt.cm.RdBu_r, cbar = False)\n",
    "# plt.title('Pearson Correlation - Total Complexity Points')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate spearman correlation heatmap of total complexity points vs. other variables\n",
    "spearman_corr = pts_prod_outflow_other_interactions.corr('spearman')\n",
    "mask = np.triu(np.ones_like(spearman_corr, dtype = bool))\n",
    "\n",
    "plt.figure(figsize = (20, 20), dpi = 300)\n",
    "sns.heatmap(spearman_corr, mask = mask, annot = True, fmt = '.2f', cmap = plt.cm.RdBu_r, cbar = False)\n",
    "plt.title('Spearman Correlation - Total Complexity Points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate scatterplots of 9MonthNet and 9MonthNetPct vs. # Pts\n",
    "fig, axs = plt.subplots(1, 2, figsize = (12, 5), dpi = 300)\n",
    "\n",
    "sns.scatterplot(x = pts_prod_outflow_other['# Pts'], \n",
    "                y = pts_prod_outflow_other['9MonthNet'], \n",
    "                s = 8, \n",
    "                ax = axs[0])\n",
    "\n",
    "sns.scatterplot(x = pts_prod_outflow_other['# Pts'], \n",
    "                y = pts_prod_outflow_other['9MonthNetPct'], \n",
    "                s = 8, \n",
    "                ax = axs[1])\n",
    "axs[1].set(ylim=(-1000, 1000))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pearson correlation heatmap of all complexity rules vs. other variables\n",
    "# pearson_corr = rules_prod_outflow_other_interactions[all_rules + other_cols].corr('pearson')\n",
    "# mask = np.triu(np.ones_like(pearson_corr, dtype = bool))\n",
    "\n",
    "# plt.figure(figsize = (32, 32), dpi = 300)\n",
    "# sns.heatmap(pearson_corr, mask = mask, annot = True, fmt = '.2f', cmap = plt.cm.RdBu_r, cbar = False)\n",
    "# plt.title('Pearson Correlation - All Complexity Rules')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate spearman correlation heatmap of all complexity rules vs. other variables\n",
    "spearman_corr = rules_prod_outflow_other_interactions[all_rules + other_cols].corr('spearman')\n",
    "mask = np.triu(np.ones_like(spearman_corr, dtype = bool))\n",
    "\n",
    "plt.figure(figsize = (32, 32), dpi = 300)\n",
    "sns.heatmap(spearman_corr, mask = mask, annot = True, fmt = '.2f', cmap = plt.cm.RdBu_r, cbar = False)\n",
    "plt.title('Spearman Correlation - All Complexity Rules')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pearson correlation heatmap of collapsed complexity rules vs. other variables\n",
    "# pearson_corr = rules_prod_outflow_other_interactions[collapsed_rules + other_cols].corr('pearson')\n",
    "# mask = np.triu(np.ones_like(pearson_corr, dtype = bool))\n",
    "\n",
    "# plt.figure(figsize = (32, 32), dpi = 300)\n",
    "# sns.heatmap(pearson_corr, mask = mask, annot = True, fmt = '.2f', cmap = plt.cm.RdBu_r, cbar = False)\n",
    "# plt.title('Pearson Correlation - Collapsed Complexity Rules')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate spearman correlation heatmap of collapsed complexity rules vs. other variables\n",
    "spearman_corr = rules_prod_outflow_other_interactions[collapsed_rules + other_cols].corr('spearman')\n",
    "mask = np.triu(np.ones_like(spearman_corr, dtype = bool))\n",
    "\n",
    "plt.figure(figsize = (32, 32), dpi = 300)\n",
    "sns.heatmap(spearman_corr, mask = mask, annot = True, fmt = '.2f', cmap = plt.cm.RdBu_r, cbar = False)\n",
    "plt.title('Spearman Correlation - Collapsed Complexity Rules')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 6), dpi = 300)\n",
    "mc = prince.MCA(n_components = 2).fit(rules_prod_outflow_other_interactions[all_rules])\n",
    "ax.set_xlabel('Component 1', fontsize = 12)\n",
    "ax.set_ylabel('Component 2', fontsize = 12)\n",
    "mc.plot_coordinates(\n",
    "    X = rules_prod_outflow_other_interactions[all_rules], \n",
    "    row_points_alpha = 0.02, \n",
    "    row_points_size = 3, \n",
    "    show_column_labels = True, \n",
    "    legend_n_cols = 4, \n",
    "    ax = ax\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 6), dpi = 300)\n",
    "mc = prince.MCA(n_components = 2).fit(rules_prod_outflow_other_interactions.loc[~(rules_prod_outflow_other_interactions[['28','29','33']].sum(axis = 1) > 0), [rule for rule in all_rules if rule not in ['28', '29', '33']]])\n",
    "ax.set_xlabel('Component 1', fontsize = 12)\n",
    "ax.set_ylabel('Component 2', fontsize = 12)\n",
    "mc.plot_coordinates(\n",
    "    X = rules_prod_outflow_other_interactions.loc[~(rules_prod_outflow_other_interactions[['28','29','33']].sum(axis = 1) > 0), [rule for rule in all_rules if rule not in ['28', '29', '33']]], \n",
    "    row_points_alpha = 0.02, \n",
    "    row_points_size = 3, \n",
    "    show_column_labels = True, \n",
    "    legend_n_cols = 5, \n",
    "    ax = ax\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 54\n",
    "Theta = (K / (K - 1.)) * (np.sum(np.square(mc.s_)**2))\n",
    "print(Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 54\n",
    "Theta = (K / (K - 1.)) * (np.sum(np.square(mc.s_)))\n",
    "print(Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pdist(rules_prod_outflow_other_interactions[all_rules], metric = 'hamming')\n",
    "mergings = linkage(distances, method = 'complete')\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12, 4), dpi = 300)\n",
    "dendrogram(mergings,\n",
    "           no_labels = True,\n",
    "           leaf_rotation = 90,\n",
    "           leaf_font_size = 6,\n",
    "           ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pdist(rules_prod_outflow_other_interactions[all_rules], metric = 'cosine')\n",
    "mergings = linkage(distances, method = 'complete')\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12, 4), dpi = 300)\n",
    "dendrogram(mergings,\n",
    "           no_labels = True,\n",
    "           leaf_rotation = 90,\n",
    "           leaf_font_size = 6,\n",
    "           ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pdist(rules_prod_outflow_other_interactions[all_rules].T, metric = 'hamming')\n",
    "mergings = linkage(distances, method = 'complete')\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12, 4), dpi = 300)\n",
    "dendrogram(mergings, \n",
    "           labels = rules_prod_outflow_other_interactions[all_rules].columns, \n",
    "           leaf_rotation = 90, \n",
    "           leaf_font_size = 6, \n",
    "           ax = ax)\n",
    "ax.tick_params(axis='x', which='major', labelsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pdist(rules_prod_outflow_other_interactions[all_rules].T, metric = 'cosine')\n",
    "mergings = linkage(distances, method = 'complete')\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12, 4), dpi = 300)\n",
    "dendrogram(mergings, \n",
    "           labels = rules_prod_outflow_other_interactions[all_rules].columns, \n",
    "           leaf_rotation = 90, \n",
    "           leaf_font_size = 6, \n",
    "           ax = ax)\n",
    "ax.tick_params(axis = 'x', which = 'major', labelsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(affinity = 'precomputed', \n",
    "                                  linkage = 'complete',\n",
    "                                  n_clusters = 5).fit(squareform(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(X = squareform(distances), labels = cluster.labels_, metric = 'precomputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clusters = 20\n",
    "\n",
    "silhouette_scores = []\n",
    "\n",
    "for n_clusters in range(2, max_clusters + 1):\n",
    "    cluster = AgglomerativeClustering(affinity = 'precomputed', \n",
    "                                      linkage = 'complete',\n",
    "                                      n_clusters = n_clusters).fit(squareform(distances))\n",
    "    \n",
    "    silhouette_scores.append(silhouette_score(squareform(distances), cluster.labels_, metric = 'precomputed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "plt.plot(range(2, max_clusters + 1), silhouette_scores)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d6140ef0c675026b0200147df87972487ebc0097827c4c765c9e0dcd9cf7b2f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
